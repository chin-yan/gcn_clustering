import os
import sys
import argparse
import numpy as np
import pickle
from sklearn.neighbors import NearestNeighbors
from pathlib import Path


class GCNDataPreparator:
    """
    Prepare data for GCN clustering from FaceNet facial encodings
    """
    
    def __init__(self, k_neighbors=80):
        """
        Initialize the GCN data preparator
        
        Args:
            k_neighbors: Number of nearest neighbors for KNN graph (default: 80, as recommended in paper)
        """
        self.k_neighbors = k_neighbors
    
    def load_facial_encodings(self, centers_data_path):
        """
        Load facial encodings from centers_data.pkl file
        
        Args:
            centers_data_path: Path to the centers_data.pkl file generated by your clustering pipeline
            
        Returns:
            facial_encodings: Dictionary mapping face image paths to 512-d feature vectors
        """
        print(f"Loading facial encodings from: {centers_data_path}")
        
        if not os.path.exists(centers_data_path):
            raise FileNotFoundError(f"File not found: {centers_data_path}")
        
        try:
            with open(centers_data_path, 'rb') as f:
                centers_data = pickle.load(f)
            
            # Extract facial_encodings from the centers_data dictionary
            if 'facial_encodings' not in centers_data:
                raise KeyError("'facial_encodings' key not found in centers_data")
            
            facial_encodings = centers_data['facial_encodings']
            
            print(f"Successfully loaded {len(facial_encodings)} facial encodings")
            
            # Verify encoding dimension (should be 512 for FaceNet)
            sample_encoding = next(iter(facial_encodings.values()))
            encoding_dim = len(sample_encoding)
            print(f"Encoding dimension: {encoding_dim}")
            
            if encoding_dim != 512:
                print(f"Warning: Expected 512-d encodings, got {encoding_dim}-d")
            
            return facial_encodings
            
        except Exception as e:
            raise RuntimeError(f"Error loading facial encodings: {e}")
    
    def convert_encodings_to_features(self, facial_encodings):
        """
        Convert facial encodings dictionary to numpy feature matrix
        
        Args:
            facial_encodings: Dictionary {image_path: feature_vector}
            
        Returns:
            features: numpy array of shape (N, D) where N is number of faces, D is feature dimension
            paths: List of image paths in the same order as features
        """
        print("Converting facial encodings to feature matrix...")
        
        # Extract paths and features in consistent order
        paths = list(facial_encodings.keys())
        
        # Stack all feature vectors into a matrix
        features_list = [facial_encodings[path] for path in paths]
        features = np.array(features_list, dtype=np.float32)
        
        print(f"Feature matrix shape: {features.shape}")
        print(f"  Number of faces: {features.shape[0]}")
        print(f"  Feature dimension: {features.shape[1]}")
        
        # Verify that features are normalized (L2 norm should be close to 1 for FaceNet)
        norms = np.linalg.norm(features, axis=1)
        mean_norm = np.mean(norms)
        print(f"Mean L2 norm of features: {mean_norm:.4f}")
        
        if mean_norm < 0.9 or mean_norm > 1.1:
            print("Warning: Features may not be normalized. Consider normalizing them.")
        
        return features, paths
    
    def build_knn_graph(self, features):
        """
        Build KNN graph for GCN clustering
        
        Args:
            features: numpy array of shape (N, D)
            
        Returns:
            knn_graph: numpy array of shape (N, k+1) where first column is node index,
                      remaining k columns are indices of k nearest neighbors
        """
        print(f"Building KNN graph with k={self.k_neighbors}...")
        
        # Use ball tree algorithm for efficient nearest neighbor search
        # We search for k+1 neighbors because the first neighbor is the node itself
        nbrs = NearestNeighbors(
            n_neighbors=self.k_neighbors + 1,
            algorithm='ball_tree',
            metric='euclidean'
        ).fit(features)
        
        # Find k+1 nearest neighbors for each node
        distances, indices = nbrs.kneighbors(features)
        
        # Format: [node_index, neighbor_1, neighbor_2, ..., neighbor_k]
        # We exclude the first neighbor (index 0) which is the node itself
        node_indices = np.arange(len(features)).reshape(-1, 1)  # (N, 1)
        neighbor_indices = indices[:, 1:self.k_neighbors+1]     # (N, k) - exclude self
        
        knn_graph = np.hstack([node_indices, neighbor_indices]).astype(np.int32)
        
        print(f"KNN graph shape: {knn_graph.shape}")
        print(f"  Format: [node_index, {self.k_neighbors} nearest neighbors]")
        
        # Verify graph construction
        print(f"Sample KNN graph entry (first node):")
        print(f"  Node: {knn_graph[0, 0]}, Neighbors: {knn_graph[0, 1:6]}...")
        
        return knn_graph
    
    def prepare_gcn_data(self, facial_encodings, output_dir):
        """
        Complete pipeline to prepare GCN data from facial encodings
        
        Args:
            facial_encodings: Dictionary of facial encodings from FaceNet
            output_dir: Directory to save prepared data
            
        Returns:
            Dictionary containing paths to saved files
        """
        print("\n" + "="*70)
        print("PREPARING GCN DATA FROM FACENET ENCODINGS")
        print("="*70 + "\n")
        
        # Create output directory
        os.makedirs(output_dir, exist_ok=True)
        
        # Step 1: Convert encodings to feature matrix
        features, paths = self.convert_encodings_to_features(facial_encodings)
        
        # Step 2: Build KNN graph
        knn_graph = self.build_knn_graph(features)
        
        # Step 3: Save all data
        print("\nSaving prepared data...")
        
        features_path = os.path.join(output_dir, 'features.npy')
        knn_graph_path = os.path.join(output_dir, 'knn_graph.npy')
        paths_path = os.path.join(output_dir, 'image_paths.pkl')
        
        # Save features
        np.save(features_path, features)
        print(f"  Features saved to: {features_path}")
        
        # Save KNN graph
        np.save(knn_graph_path, knn_graph)
        print(f"  KNN graph saved to: {knn_graph_path}")
        
        # Save image paths for result mapping
        with open(paths_path, 'wb') as f:
            pickle.dump(paths, f)
        print(f"  Image paths saved to: {paths_path}")
        
        # Create metadata file
        metadata = {
            'num_faces': len(features),
            'feature_dim': features.shape[1],
            'k_neighbors': self.k_neighbors,
            'features_path': features_path,
            'knn_graph_path': knn_graph_path,
            'paths_path': paths_path
        }
        
        metadata_path = os.path.join(output_dir, 'metadata.pkl')
        with open(metadata_path, 'wb') as f:
            pickle.dump(metadata, f)
        print(f"  Metadata saved to: {metadata_path}")
        
        print("\n" + "="*70)
        print("GCN DATA PREPARATION COMPLETE")
        print("="*70)
        print("\nYou can now run GCN clustering with:")
        print(f"python gcn_clustering/test.py \\")
        print(f"    --val_feat_path {features_path} \\")
        print(f"    --val_knn_graph_path {knn_graph_path} \\")
        print(f"    --checkpoint gcn_clustering/logs/logs/best.ckpt \\")
        print(f"    --k-at-hop 80 5 \\")
        print(f"    --active_connection 5")
        print("="*70 + "\n")
        
        return metadata


def prepare_from_centers_data(centers_data_path, output_dir, k_neighbors=80):
    """
    Convenience function to prepare GCN data directly from centers_data.pkl
    
    Args:
        centers_data_path: Path to centers_data.pkl file
        output_dir: Output directory for GCN data
        k_neighbors: Number of neighbors for KNN graph (default: 80)
        
    Returns:
        metadata: Dictionary containing information about prepared data
    """
    preparator = GCNDataPreparator(k_neighbors=k_neighbors)
    
    # Load facial encodings from centers_data.pkl
    facial_encodings = preparator.load_facial_encodings(centers_data_path)
    
    # Prepare GCN data
    metadata = preparator.prepare_gcn_data(facial_encodings, output_dir)
    
    return metadata


def main():
    """Main function for command line usage"""
    parser = argparse.ArgumentParser(
        description='Prepare facial features and KNN graph for GCN clustering'
    )
    
    parser.add_argument(
        '--input_encodings',
        type=str,
        required=True,
        help='Path to centers_data.pkl containing FaceNet encodings'
    )
    
    parser.add_argument(
        '--output_dir',
        type=str,
        required=True,
        help='Output directory for GCN data files'
    )
    
    parser.add_argument(
        '--k_neighbors',
        type=int,
        default=80,
        help='Number of nearest neighbors for KNN graph (default: 80)'
    )
    
    args = parser.parse_args()
    
    # Prepare GCN data
    try:
        metadata = prepare_from_centers_data(
            centers_data_path=args.input_encodings,
            output_dir=args.output_dir,
            k_neighbors=args.k_neighbors
        )
        
        print("Success! GCN data preparation completed.")
        return 0
        
    except Exception as e:
        print(f"\nError: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    sys.exit(main())